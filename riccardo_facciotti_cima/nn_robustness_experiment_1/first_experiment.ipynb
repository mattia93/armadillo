{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# First experiment\n",
    "## Basic network, one hidden layer, only hidden activation function are modified\n"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this experiment we are going to test the robustness of neural networks in a very basic configuration, using Activation Function in the hidden layer as a changing parameter.\n",
    "The constant characteristics of the networks are:\n",
    "* Dataset = fashon_mnist\n",
    "* Loss = cathegorical crossentropy\n",
    "* Output activation = softmax\n",
    "* Number of hidden layers = 1\n",
    "* Early stopping metric =  val_loss with patience 10\n",
    "\n",
    "After having our models correctly set up, we are going to attack them and measure their robustness according to some metrics (before and after attack):\n",
    "* Accuracy\n",
    "* Precision\n",
    "* Recall\n",
    "* Max and min confidence\n",
    "* Confusion matrix\n",
    "* Most and least robust class\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Imports"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "from functions import *\n",
    "#plt.rcParams[\"figure.figsize\"] = (10, 8)\n",
    "import time\n",
    "import gc\n",
    "from PIL import Image\n",
    "import glob\n",
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Data Load and Preprocessing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set:  (60000, 28, 28)\n",
      "Test set:  (10000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "train_images = train_images.astype(\"float32\") / 255\n",
    "test_images = test_images.astype(\"float32\") / 255\n",
    "\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "print(\"Train set: \", train_images.shape)\n",
    "print(\"Test set: \", test_images.shape)\n",
    "\n",
    "# divide data into classes\n",
    "subsets = []\n",
    "n_classes = 10\n",
    "for i in range(n_classes):\n",
    "    tmp_list = []\n",
    "    for j in range(test_images.shape[0]):\n",
    "        c = np.nonzero(test_labels[j])[0][0]\n",
    "        if c == i:\n",
    "            tmp_list.append(test_images[j])\n",
    "    tmp_list = np.array(tmp_list)\n",
    "    subsets.append(tmp_list)\n",
    "# now we have subsets which is a 10-elements list containing arrays of same class images\n",
    "\n",
    "new_test_images = np.zeros((0,28,28))\n",
    "for i in range(len(subsets)):\n",
    "    new_test_images = np.concatenate((new_test_images, subsets[i]))\n",
    "# now we have new_test_images which is test_images sorted by class\n",
    "\n",
    "new_test_labels = np.zeros((0,n_classes))\n",
    "for i in range(n_classes):\n",
    "    tmp = np.zeros((subsets[i].shape[0],n_classes))\n",
    "    tmp[:,i] = 1\n",
    "    new_test_labels = np.concatenate((new_test_labels, tmp))\n",
    "# now we have new_test_labels which is test_labels sorted to fit subsets"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Build and Train Models"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network training with ativation function = \"sigmoid\"\n",
      "Epoch 1/30\n",
      "375/375 [==============================] - 3s 9ms/step - loss: 0.6252 - accuracy: 0.7810 - val_loss: 0.5269 - val_accuracy: 0.8043\n",
      "Epoch 2/30\n",
      "141/375 [==========>...................] - ETA: 1s - loss: 0.4489 - accuracy: 0.8389"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Input \u001B[1;32mIn [10]\u001B[0m, in \u001B[0;36m<cell line: 1>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     12\u001B[0m mc \u001B[38;5;241m=\u001B[39m ModelCheckpoint(filepath\u001B[38;5;241m=\u001B[39mpath, monitor\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mval_loss\u001B[39m\u001B[38;5;124m\"\u001B[39m, mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmin\u001B[39m\u001B[38;5;124m\"\u001B[39m, save_best_only\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n\u001B[0;32m     13\u001B[0m cb_list \u001B[38;5;241m=\u001B[39m [es, mc]\n\u001B[1;32m---> 15\u001B[0m h \u001B[38;5;241m=\u001B[39m \u001B[43mnetwork\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfit\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtrain_images\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtrain_labels\u001B[49m\u001B[43m,\u001B[49m\u001B[43mbatch_size\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mBATCH_SIZE\u001B[49m\u001B[43m,\u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mEPOCHS\u001B[49m\u001B[43m,\u001B[49m\u001B[43mvalidation_split\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mVALIDATION_SPLIT\u001B[49m\u001B[43m,\u001B[49m\u001B[43mcallbacks\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcb_list\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:108\u001B[0m, in \u001B[0;36menable_multi_worker.<locals>._method_wrapper\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m    106\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_method_wrapper\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs):\n\u001B[0;32m    107\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_in_multi_worker_mode():  \u001B[38;5;66;03m# pylint: disable=protected-access\u001B[39;00m\n\u001B[1;32m--> 108\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mmethod\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    110\u001B[0m   \u001B[38;5;66;03m# Running inside `run_distribute_coordinator` already.\u001B[39;00m\n\u001B[0;32m    111\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m dc_context\u001B[38;5;241m.\u001B[39mget_current_worker_context():\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py:1098\u001B[0m, in \u001B[0;36mModel.fit\u001B[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001B[0m\n\u001B[0;32m   1091\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m trace\u001B[38;5;241m.\u001B[39mTrace(\n\u001B[0;32m   1092\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTraceContext\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1093\u001B[0m     graph_type\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtrain\u001B[39m\u001B[38;5;124m'\u001B[39m,\n\u001B[0;32m   1094\u001B[0m     epoch_num\u001B[38;5;241m=\u001B[39mepoch,\n\u001B[0;32m   1095\u001B[0m     step_num\u001B[38;5;241m=\u001B[39mstep,\n\u001B[0;32m   1096\u001B[0m     batch_size\u001B[38;5;241m=\u001B[39mbatch_size):\n\u001B[0;32m   1097\u001B[0m   callbacks\u001B[38;5;241m.\u001B[39mon_train_batch_begin(step)\n\u001B[1;32m-> 1098\u001B[0m   tmp_logs \u001B[38;5;241m=\u001B[39m \u001B[43mtrain_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43miterator\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1099\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m data_handler\u001B[38;5;241m.\u001B[39mshould_sync:\n\u001B[0;32m   1100\u001B[0m     context\u001B[38;5;241m.\u001B[39masync_wait()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:780\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    778\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    779\u001B[0m   compiler \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mnonXla\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m--> 780\u001B[0m   result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    782\u001B[0m new_tracing_count \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tracing_count()\n\u001B[0;32m    783\u001B[0m without_tracing \u001B[38;5;241m=\u001B[39m (tracing_count \u001B[38;5;241m==\u001B[39m new_tracing_count)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\def_function.py:807\u001B[0m, in \u001B[0;36mFunction._call\u001B[1;34m(self, *args, **kwds)\u001B[0m\n\u001B[0;32m    804\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n\u001B[0;32m    805\u001B[0m   \u001B[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001B[39;00m\n\u001B[0;32m    806\u001B[0m   \u001B[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001B[39;00m\n\u001B[1;32m--> 807\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_stateless_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwds\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# pylint: disable=not-callable\u001B[39;00m\n\u001B[0;32m    808\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_stateful_fn \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    809\u001B[0m   \u001B[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001B[39;00m\n\u001B[0;32m    810\u001B[0m   \u001B[38;5;66;03m# in parallel.\u001B[39;00m\n\u001B[0;32m    811\u001B[0m   \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock\u001B[38;5;241m.\u001B[39mrelease()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:2829\u001B[0m, in \u001B[0;36mFunction.__call__\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   2827\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_lock:\n\u001B[0;32m   2828\u001B[0m   graph_function, args, kwargs \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_maybe_define_function(args, kwargs)\n\u001B[1;32m-> 2829\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mgraph_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_filtered_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1843\u001B[0m, in \u001B[0;36mConcreteFunction._filtered_call\u001B[1;34m(self, args, kwargs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1827\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_filtered_call\u001B[39m(\u001B[38;5;28mself\u001B[39m, args, kwargs, cancellation_manager\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m):\n\u001B[0;32m   1828\u001B[0m   \u001B[38;5;124;03m\"\"\"Executes the function, filtering arguments from the Python function.\u001B[39;00m\n\u001B[0;32m   1829\u001B[0m \n\u001B[0;32m   1830\u001B[0m \u001B[38;5;124;03m  Objects aside from Tensors, CompositeTensors, and Variables are ignored.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m   1841\u001B[0m \u001B[38;5;124;03m    `args` and `kwargs`.\u001B[39;00m\n\u001B[0;32m   1842\u001B[0m \u001B[38;5;124;03m  \"\"\"\u001B[39;00m\n\u001B[1;32m-> 1843\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_flat\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1844\u001B[0m \u001B[43m      \u001B[49m\u001B[43m[\u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mt\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mnest\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mflatten\u001B[49m\u001B[43m(\u001B[49m\u001B[43m(\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mexpand_composites\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mTrue\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[0;32m   1845\u001B[0m \u001B[43m       \u001B[49m\u001B[38;5;28;43;01mif\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43misinstance\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mt\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m(\u001B[49m\u001B[43mops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTensor\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1846\u001B[0m \u001B[43m                         \u001B[49m\u001B[43mresource_variable_ops\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mBaseResourceVariable\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1847\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcaptured_inputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcaptured_inputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m   1848\u001B[0m \u001B[43m      \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:1923\u001B[0m, in \u001B[0;36mConcreteFunction._call_flat\u001B[1;34m(self, args, captured_inputs, cancellation_manager)\u001B[0m\n\u001B[0;32m   1918\u001B[0m possible_gradient_type \u001B[38;5;241m=\u001B[39m (\n\u001B[0;32m   1919\u001B[0m     pywrap_tfe\u001B[38;5;241m.\u001B[39mTFE_Py_TapeSetPossibleGradientTypes(args))\n\u001B[0;32m   1920\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (possible_gradient_type \u001B[38;5;241m==\u001B[39m _POSSIBLE_GRADIENT_TYPES_NONE\n\u001B[0;32m   1921\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m executing_eagerly):\n\u001B[0;32m   1922\u001B[0m   \u001B[38;5;66;03m# No tape is watching; skip to running the function.\u001B[39;00m\n\u001B[1;32m-> 1923\u001B[0m   \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_build_call_outputs(\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_inference_function\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcall\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m   1924\u001B[0m \u001B[43m      \u001B[49m\u001B[43mctx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcancellation_manager\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcancellation_manager\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m   1925\u001B[0m forward_backward \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_select_forward_and_backward_functions(\n\u001B[0;32m   1926\u001B[0m     args,\n\u001B[0;32m   1927\u001B[0m     possible_gradient_type,\n\u001B[0;32m   1928\u001B[0m     executing_eagerly)\n\u001B[0;32m   1929\u001B[0m forward_function, args_with_tangents \u001B[38;5;241m=\u001B[39m forward_backward\u001B[38;5;241m.\u001B[39mforward()\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\function.py:545\u001B[0m, in \u001B[0;36m_EagerDefinedFunction.call\u001B[1;34m(self, ctx, args, cancellation_manager)\u001B[0m\n\u001B[0;32m    543\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m _InterpolateFunctionError(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    544\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m cancellation_manager \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 545\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mexecute\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mexecute\u001B[49m\u001B[43m(\u001B[49m\n\u001B[0;32m    546\u001B[0m \u001B[43m        \u001B[49m\u001B[38;5;28;43mstr\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msignature\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mname\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    547\u001B[0m \u001B[43m        \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_num_outputs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    548\u001B[0m \u001B[43m        \u001B[49m\u001B[43minputs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    549\u001B[0m \u001B[43m        \u001B[49m\u001B[43mattrs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m    550\u001B[0m \u001B[43m        \u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mctx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    551\u001B[0m   \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    552\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m execute\u001B[38;5;241m.\u001B[39mexecute_with_cancellation(\n\u001B[0;32m    553\u001B[0m         \u001B[38;5;28mstr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msignature\u001B[38;5;241m.\u001B[39mname),\n\u001B[0;32m    554\u001B[0m         num_outputs\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_outputs,\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    557\u001B[0m         ctx\u001B[38;5;241m=\u001B[39mctx,\n\u001B[0;32m    558\u001B[0m         cancellation_manager\u001B[38;5;241m=\u001B[39mcancellation_manager)\n",
      "File \u001B[1;32m~\\miniconda3\\envs\\nn-robustness\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:59\u001B[0m, in \u001B[0;36mquick_execute\u001B[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001B[0m\n\u001B[0;32m     57\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m     58\u001B[0m   ctx\u001B[38;5;241m.\u001B[39mensure_initialized()\n\u001B[1;32m---> 59\u001B[0m   tensors \u001B[38;5;241m=\u001B[39m \u001B[43mpywrap_tfe\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mTFE_Py_Execute\u001B[49m\u001B[43m(\u001B[49m\u001B[43mctx\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_handle\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdevice_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mop_name\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     60\u001B[0m \u001B[43m                                      \u001B[49m\u001B[43minputs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mattrs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_outputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m core\u001B[38;5;241m.\u001B[39m_NotOkStatusException \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m     62\u001B[0m   \u001B[38;5;28;01mif\u001B[39;00m name \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    network = models.Sequential()\n",
    "    network.add(layers.Flatten())\n",
    "    network.add(layers.Dense(DEEP_NEURONS,activation=function,input_shape=INPUT_SHAPE,kernel_initializer=initializer,))\n",
    "    network.add(layers.Dense(10, activation=OUT_ACTIVATION))\n",
    "    network.compile(optimizer=OPTIMIZER, loss=LOSS, metrics=METRICS)\n",
    "\n",
    "    print(f'Network training with ativation function = \"{function}\"')\n",
    "\n",
    "    es = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=ES_PATIENCE)\n",
    "    path = MODELS_PATH+\"/best_\" + function + \".h5\"\n",
    "    mc = ModelCheckpoint(filepath=path, monitor=\"val_loss\", mode=\"min\", save_best_only=True)\n",
    "    cb_list = [es, mc]\n",
    "\n",
    "    h = network.fit(train_images,train_labels,batch_size=BATCH_SIZE,epochs=EPOCHS,validation_split=VALIDATION_SPLIT,callbacks=cb_list)\n",
    "\n",
    "    # At this point we have best models saved in \"best_models\" folder"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Model Metrics Evaluation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    print(f'Evaluate model with hidden activation function \"{function}\"...')\n",
    "    name = MODELS_PATH+\"/best_\" + function + \".h5\"\n",
    "    model = load_model(name)\n",
    "    metrics_name = \"scores_best_\"+function\n",
    "    m = ModelMetrics(metrics_name, new_test_images, new_test_labels, model.predict(new_test_images))\n",
    "    m.buil_metrics()\n",
    "    path = SCORES_PATH+\"/\"+metrics_name\n",
    "    save_object(m, path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The attack consists of these steps:\n",
    "1. select the model\n",
    "2. take the test set and, for each class, find the most vulnerable pixel and the corresponding value (i.e. x,y,z)\n",
    "3. modify the entire test set changing the pixel values found in the previous step\n",
    "4. evaluate all the metrics of the selected model with the modified test set\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Prepare Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def objective(trial, m, test, current_class):\n",
    "\n",
    "    xp = trial.suggest_int(\"xp\", MIN_XP, MAX_XP)\n",
    "    yp = trial.suggest_int(\"yp\", MIN_YP, MAX_XP)\n",
    "    value = trial.suggest_uniform(\"zp\", MIN_ZP, MAX_ZP)\n",
    "\n",
    "    new_test_labels = np.zeros((test.shape[0],10))\n",
    "    new_test_labels[:,current_class] = 1\n",
    "\n",
    "    tmp = np.copy(test)\n",
    "    tmp[:,xp,yp] = value\n",
    "\n",
    "    # minimize loss\n",
    "\n",
    "    return m.evaluate(tmp,new_test_labels, verbose=0)[1]\n",
    "\n",
    "def print_best_callback(study, trial):\n",
    "    print(f\"#Trial: {trial.number}, Best value: {study.best_value}, Best params: {study.best_trial.params}\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perform Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "for function, initializer in DEEP_ACTIVATION.items(): # 7\n",
    "    model_name = MODELS_PATH+\"/best_\" + function + \".h5\"\n",
    "    model = load_model(model_name)\n",
    "    new_attacked_test_images = np.zeros((0,28,28))\n",
    "    for i in CLASS_NAMES: # 10\n",
    "\n",
    "        if not VERBOSITY:\n",
    "            optuna.logging.set_verbosity(optuna.logging.WARNING)\n",
    "\n",
    "        func = lambda trial: objective(trial, model, subsets[i], i)\n",
    "\n",
    "        study_name = f\"study_{function}_{i}\"\n",
    "        storage_name = f\"sqlite:///{STUDY_DB_PATH}/{study_name}.db\"\n",
    "        study = optuna.create_study(study_name=study_name, storage=storage_name,direction=DIRECTION, sampler=SAMPLER)\n",
    "        study.optimize(func, n_trials=N_TRIALS, timeout=TIMEOUT, callbacks=[print_best_callback])\n",
    "\n",
    "\n",
    "# 2048 = 35742.56469321251 seconds = x hours\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Visualize Attack"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Data preparation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    accuracy_trend = {0:load_object(SCORES_PATH+\"/scores_best_\"+function).accuracy}\n",
    "    for c in range(N_CHECKPOINTS):\n",
    "        attacked_test_images = np.zeros((0,28,28))\n",
    "        x = (c+1)*int((N_TRIALS/N_CHECKPOINTS))\n",
    "        for i in CLASS_NAMES:\n",
    "            study_name = f\"study_{function}_{i}\"\n",
    "            storage_name = f\"sqlite:///{STUDY_DB_PATH}/{study_name}.db\"\n",
    "            study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "            df = study.trials_dataframe(attrs=(\"value\", \"params\"))\n",
    "\n",
    "            idx = df['value'].head(x).idxmin()\n",
    "\n",
    "            xp = df['params_xp'][idx]\n",
    "            yp = df['params_yp'][idx]\n",
    "            zp = df['params_zp'][idx]\n",
    "\n",
    "            sub_attacked_test_images = np.copy(subsets[i])\n",
    "            sub_attacked_test_images[:,xp,yp] = zp\n",
    "            attacked_test_images = np.concatenate((attacked_test_images, sub_attacked_test_images))\n",
    "        # here we have attacked_test_images correctly built\n",
    "        metrics_name = \"acc_trend_\"+function\n",
    "        name = MODELS_PATH+\"/best_\" + function + \".h5\"\n",
    "        model = load_model(name)\n",
    "        m = ModelMetrics(metrics_name, attacked_test_images, new_test_labels, model.predict(attacked_test_images))\n",
    "        m.buil_metrics()\n",
    "        if c==(N_CHECKPOINTS-1):\n",
    "            path = SCORES_PATH+\"/scores_best_\"+function+\"_best_attack\"\n",
    "            save_object(m, path)\n",
    "        accuracy_trend[x] = m.accuracy\n",
    "        del m\n",
    "        gc.collect()\n",
    "    path = SCORES_PATH+\"/\"+metrics_name\n",
    "    save_object(accuracy_trend, path)\n",
    "    # here we have saved attacked models metrics for each checkpoint for one function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    for i in CLASS_NAMES:\n",
    "        study_name = f\"study_{function}_{i}\"\n",
    "        storage_name = f\"sqlite:///{STUDY_DB_PATH}/{study_name}.db\"\n",
    "        study = optuna.create_study(study_name=study_name, storage=storage_name, load_if_exists=True)\n",
    "        fig = optuna.visualization.matplotlib.plot_contour(study, params=['xp', 'yp'], target_name='')\n",
    "        fig.invert_yaxis()\n",
    "        fig.set_title(f\"Function=\"+r\"$\\bf{\" + function + \"}$\"+\", Class=\"+r\"$\\bf{\" + CLASS_NAMES[i] + \"}$\", fontsize=20)\n",
    "        path = f\"{ATTACK_SURFACE_FIG_PATH}/attack_surface_{function}_{i}.png\"\n",
    "        plt.savefig(path)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from numpy import asarray\n",
    "columns = len(DEEP_ACTIVATION)\n",
    "rows = len(CLASS_NAMES)\n",
    "\n",
    "image_list = []\n",
    "for filename in glob.glob(ATTACK_SURFACE_FIG_PATH+\"/*.png\"): #assuming gif\n",
    "    im=Image.open(filename)\n",
    "    im = asarray(im)\n",
    "    image_list.append(im)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Table \"functions vs classes\" of attack surface"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(nrows=rows, ncols=columns, figsize=(18,18))\n",
    "img_count = 0\n",
    "for i in range(rows):\n",
    "    for j in range(columns):\n",
    "        if img_count < len(image_list):\n",
    "            axes[i, j].imshow(image_list[img_count])\n",
    "            img_count+=1"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Accuracy trend for each function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    d = load_object(f\"./scores/acc_trend_{function}\")\n",
    "    keys = np.fromiter(d.keys(), dtype=int)\n",
    "    vals = np.fromiter(d.values(), dtype=float)\n",
    "    print(f\"base-model accuracy:{vals[0]}\\n2048-optuna-iterations-model accuracy:{vals[-1]}\\ndifference:%.4f\" % (vals[0]-vals[-1]))\n",
    "\n",
    "    plt.plot(keys, vals, label = \"line 1\")\n",
    "    plt.title(f'Optuna progress on {function} model accuracy')\n",
    "    plt.xlabel('optuna iterations')\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Best attack for each function"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "for function, initializer in DEEP_ACTIVATION.items():\n",
    "    m1 = load_object(SCORES_PATH+\"/scores_best_\"+function)\n",
    "    m2 = load_object(SCORES_PATH+\"/scores_best_\"+function+\"_best_attack\")\n",
    "    m = load_model(MODELS_PATH+\"/best_\"+function+\".h5\")\n",
    "    best_attack = 0\n",
    "    maximum = 0\n",
    "    for i in range (len(m1.y_true)): # per ogni immagine\n",
    "        j = np.nonzero(m1.y_true[i])[0][0] # predizione vera\n",
    "        k = abs(m1.y_pred[i][j] - m2.y_pred[i][j])\n",
    "        if k >= maximum:\n",
    "            maximum = k\n",
    "            best_attack = i\n",
    "\n",
    "    print(f\"index={best_attack} value={maximum}\")\n",
    "    plot_attack(m1.x_test[best_attack], m2.x_test[best_attack], m, function)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}